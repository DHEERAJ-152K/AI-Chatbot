# AI-Chatbot

AI-powered customer support chat with React frontend and Node.js/TypeScript backend using **Google Gemini 2.0 Flash** and **SQLite**.

---

## How to Run Locally

### Prerequisites
- Node.js 18+
- Google API Key from https://aistudio.google.com/app/apikey

### Backend Setup

```bash
cd server
npm install

# Create .env file
# Add your GOOGLE_API_KEY to .env

npm run dev
```

Backend runs at `http://localhost:5000`

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend runs at `http://localhost:5173`

---

## Database Setup

**No manual setup required!** SQLite database (`chat.db`) is automatically created on first run.

**Schema:**
```sql
conversations (id, created_at, metadata)
messages (id, conversation_id, sender, text, timestamp)
```

**Reset database:** Delete `backend/chat.db` and restart server.

---

## âš™ï¸ Environment Variables

### Backend `.env`

```env
PORT=5000 or 3000
NODE_ENV=development
GOOGLE_API_KEY=your_google_api_key_here
```


---

## ğŸ—ï¸ Architecture Overview

### Backend Structure - Layered Design

```
Routes (API endpoints)
    â†“
Controllers (HTTP handling)
    â†“
Services (Business logic)
    â†“
Repositories (Data access)
    â†“
Database (SQLite)
```

### Folder Structure

```
backend/src/
â”œâ”€â”€ routes/           # API endpoint definitions
â”œâ”€â”€ controllers/      # Request/response handling
â”œâ”€â”€ services/         # Business logic + LLM integration
â”œâ”€â”€ repositories/     # Database operations
â”œâ”€â”€ db/              # SQLite implementation
â”œâ”€â”€ middleware/       # Validation, error handling
â””â”€â”€ types/           # TypeScript types
```

### Key Design Decisions

**1. Layered Architecture**
- Clean separation of concerns
- Easy to test and maintain
- Can swap any layer independently

**2. Repository Pattern**
- Database-agnostic code
- Easy migration (SQLite â†’ PostgreSQL) RDBMS
- Clean data access interface

**3. Service Encapsulation**
- LLM logic isolated in `llmService`
- Easy to switch AI providers
- Centralized prompt management

**4. Middleware Pipeline**
- Input validation before business logic
- Consistent error handling
- Ready for authentication

---

## ğŸ¤– LLM Integration

### Provider: Google Gemini 2.0 Flash

**Model:** `gemini-2.0-flash`

**Why Gemini?**
- Fast responses 
- Free during preview (with limited RPM)
- Excellent instruction following
- Built-in safety filters

### Prompting Strategy

**System Instruction:** Store knowledge (shipping, returns, support hours, payments, warranty) provided as system prompt.

**Conversation History:** Last 10 messages sent for context.

**Configuration:**
```typescript
{
  maxOutputTokens: 500,     // Control response length
  temperature: 0.7          // Balance creativity/consistency
}
```

**Sample Prompt Flow:**
```
System: "You are a support agent for TechHub Store..."
History: [last 10 messages]
User: "How long does shipping take?"
â†’ AI generates contextual response
```

**Error Handling:**
- Invalid API key â†’ Clear error message
- Rate limits â†’ User-friendly retry message
- Safety filters â†’ Polite deflection
- Network errors â†’ Graceful fallback

---

## âš–ï¸ Trade-offs & Design Choices

### Trade-offs Made

**SQLite vs PostgreSQL**
- âœ… Chose: SQLite
- Why: Zero configuration, perfect for demo/MVP
- Trade-off: Limited concurrency vs full-featured RDBMS
- Migration path: Repository pattern makes PostgreSQL swap trivial

**In-Memory History vs Full Context**
- âœ… Chose: Last 10 messages only
- Why: Balance context quality with cost/performance
- Trade-off: Older context lost vs unbounded token usage

**Single LLM Provider**
- âœ… Chose: Gemini only
- Why: Fast, free, simple integration
- Trade-off: Vendor lock-in vs abstraction complexity
- Note: Service layer makes provider swap easy


---

## ğŸš§ If I Had More Time...

### Database
- **PostgreSQL migration** with ORM
- **Redis caching** for conversation history
- **Database indexes optimization** for scale
- **Backup/restore** automation

### Features
- **Multi-channel support**: WhatsApp, Instagram DM integration
- **File uploads**: Support images, documents in chat
- **Agent handoff**: Escalate to human support on request
- **Sentiment analysis**: Detect frustrated users

### LLM Enhancements
- **Function calling**: Order lookup, tracking, cancellation
- **Multi-provider fallback**: Gemini â†’ OpenAI â†’ Claude

### Production Readiness
- **Authentication**: JWT-based user auth
- **Rate limiting**: Per-user API quotas with Redis
- **Monitoring**: Logging (Winston), metrics (Prometheus)
- **CI/CD**: GitHub Actions pipeline
- **API documentation**: OpenAPI/Swagger 

### UX Improvements
- **Voice input**: Speech-to-text integration
- **Suggested replies**: Context-aware quick responses
- **Rich messages**: Cards, carousels, buttons
- **Multi-language**: With auto-detection

### Performance
- **Response caching**: Cache common questions
- **CDN integration**: Static asset delivery
- **Load balancing**: Horizontal scaling

---

## ğŸ“Š Current Limitations

- **Concurrency**: SQLite handles moderate load only
- **No Auth**: Anonymous conversations only
- **Single Region**: No geographic redundancy
- **No Monitoring**: Manual log inspection

All limitations have clear upgrade paths documented above.

---

## ğŸ¯ What's Production-Ready

âœ… **Core functionality**: Complete chat flow works  
âœ… **Error handling**: Graceful failures, no crashes  
âœ… **Input validation**: All edge cases covered  
âœ… **Code quality**: Clean, typed, well-structured  
âœ… **Database**: ACID compliant with proper schema  
âœ… **Extensibility**: Easy to add channels/features  

---
